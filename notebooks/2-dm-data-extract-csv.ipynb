{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON content has been cleaned and saved back to files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "def extract_and_clean_json(directory):\n",
    "    \"\"\"\n",
    "    Processes JSON files in a directory, removes unnecessary ```json ... ``` blocks,\n",
    "    retains only the valid JSON content, and cleans the surrounding text.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with codecs.open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "                        content = file.read()\n",
    "                        json_start = content.find(\"```json\")\n",
    "                        json_end = content.rfind(\"```\")\n",
    "                        if json_start != -1 and json_end != -1:\n",
    "                            json_content = content[json_start + 7:json_end].strip()\n",
    "                            content = json_content\n",
    "                        else:\n",
    "                            content = content\n",
    "\n",
    "                    with codecs.open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                        file.write(content)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"../output_json\"\n",
    "extract_and_clean_json(directory_path)\n",
    "\n",
    "print(\"JSON content has been cleaned and saved back to files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON content has been cleaned, including comments, and saved back to files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import codecs\n",
    "\n",
    "def extract_and_clean_json(directory):\n",
    "    \"\"\"\n",
    "    Processes JSON files in a directory, removes unnecessary ```json ... ``` blocks,\n",
    "    retains only the valid JSON content, and cleans the surrounding text, including comments.\n",
    "    \"\"\"\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with codecs.open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "                        content = file.read()\n",
    "                        json_start = content.find(\"```json\")\n",
    "                        json_end = content.rfind(\"```\")\n",
    "                        if json_start != -1 and json_end != -1:\n",
    "                            json_content = content[json_start + 7:json_end].strip()\n",
    "                            # Remove comments\n",
    "                            json_content = re.sub(r\"//.*?(\\n|$)|/\\*.*?\\*/\", \"\", json_content, flags=re.DOTALL)\n",
    "                            # Retain only valid JSON content\n",
    "                            content = json_content\n",
    "                        else:\n",
    "                            # If no ```json block found, use the content as is\n",
    "                            content = content\n",
    "\n",
    "                    # Save the cleaned JSON content back to the file\n",
    "                    with codecs.open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                        file.write(content)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file {file_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"../output_json\"\n",
    "extract_and_clean_json(directory_path)\n",
    "\n",
    "print(\"JSON content has been cleaned, including comments, and saved back to files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: Accountant\n",
      "Company: Company Name\n",
      "Summary: In this position as an Accountant assigned to the Defense Enterprise Accounting and Management System (DEAMS) ERO I was responsible for identifying and resolving issues affecting the DEAMS General Ledger.\n",
      "Highlights: Served on a tiger team which identified and resolved General Ledger postings in DEAMS totaling $360B in accounting adjustments., In collaboration with DFAS Europe, developed an automated tool that identified duplicate obligations.\n",
      "\n",
      "Position: Resource Advisor\n",
      "Company: Company Name\n",
      "Summary: In this position as Resource Advisor for the 1st Air Communications Operation Squadron (1ACOS) I was responsible for providing financial advice and decision support to the Commander.\n",
      "\n",
      "Position: Staff Accountant\n",
      "Company: Company Name\n",
      "Summary: In my position as the Staff Accountant for HQ USAFE I was responsible for providing accounting and financial oversight and advice to customers throughout the Command in support of the USAFE Comptroller.\n",
      "Highlights: In collaboration with DFAS Europe, developed an automated tool that identifies duplicate obligations by comparing records in the accounting system to the contracting system and provided notification to the funds manager for review and resolution.\n",
      "\n",
      "Position: Chief, Reports Branch. Accounts Maintenance and Control\n",
      "Company: Company Name\n",
      "Summary: In my position as Chief of the Reports Branch in Accounts Maintenance & Control (AM&C) I was responsible for ensuring the development and standardization of various managerial and system reports.\n",
      "Highlights: Worked with staff to reduce reconciliations from $6.9 million in February 2007 to $1.1 million in August, accomplished this despite loss in experienced personnel and realigning resources to support critical initiatives in Accounts Payable.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "file_path = '..\\\\output_json\\\\ACCOUNTANT\\\\10554236.json'\n",
    "\n",
    "# Load JSON from a file\n",
    "with open(file_path, 'r') as file:\n",
    "    cv_data = json.load(file)\n",
    "\n",
    "# Extract 'work' section and combine them into a paragraph\n",
    "work_paragraph = \"\"\n",
    "for work in cv_data.get('work', []):\n",
    "    work_summary = work.get('summary', '')\n",
    "    work_highlights = ', '.join(work.get('highlights', []))\n",
    "    if work_summary or work_highlights:\n",
    "        work_paragraph += f\"Position: {work.get('position', '')}\\n\"\n",
    "        work_paragraph += f\"Company: {work.get('name', '')}\\n\"\n",
    "        work_paragraph += f\"Summary: {work_summary}\\n\"\n",
    "        if work_highlights:\n",
    "            work_paragraph += f\"Highlights: {work_highlights}\\n\"\n",
    "        work_paragraph += \"\\n\"\n",
    "\n",
    "# Display the paragraph\n",
    "print(work_paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               work\n",
      "0  10554236  Position: Accountant\\nCompany: Company Name\\nS...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Get the filename from the path\n",
    "file_path = '..\\\\output_json\\\\ACCOUNTANT\\\\10554236.json'\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Extract the id from the filename\n",
    "cv_id = os.path.splitext(file_name)[0]  # Assuming the format is something like '10554236.json'\n",
    "\n",
    "# Load JSON from the file\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        cv_data = json.load(file)\n",
    "\n",
    "    # Extract 'work' section and combine them into a paragraph\n",
    "    work_paragraph = \"\"\n",
    "    for work in cv_data.get('work', []):\n",
    "        work_summary = work.get('summary', '')\n",
    "        work_highlights = ', '.join(work.get('highlights', []))\n",
    "        if work_summary or work_highlights:\n",
    "            work_paragraph += f\"Position: {work.get('position', '')}\\n\"\n",
    "            work_paragraph += f\"Company: {work.get('name', '')}\\n\"\n",
    "            work_paragraph += f\"Summary: {work_summary}\\n\"\n",
    "            if work_highlights:\n",
    "                work_paragraph += f\"Highlights: {work_highlights}\\n\"\n",
    "            work_paragraph += \"\\n\"\n",
    "\n",
    "    # Create a DataFrame with 'id' and 'work' columns\n",
    "    df = pd.DataFrame({'id': [cv_id], 'work': [work_paragraph]})\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Institution: Northern Maine Community College\n",
      "Area of Study: Accounting\n",
      "Degree: Associate\n",
      "Start Date: \n",
      "End Date: 1994\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = '..\\\\output_json\\\\ACCOUNTANT\\\\10554236.json'\n",
    "\n",
    "# Load JSON from a file\n",
    "with open(file_path, 'r') as file:\n",
    "    cv_data = json.load(file)\n",
    "\n",
    "# Extract 'education' section and combine them into a paragraph\n",
    "education_paragraph = \"\"\n",
    "for education in cv_data.get('education', []):\n",
    "    institution = education.get('institution', '')\n",
    "    area = education.get('area', '')\n",
    "    study_type = education.get('studyType', '')\n",
    "    start_date = education.get('startDate', '')\n",
    "    end_date = education.get('endDate', '')\n",
    "    courses = ', '.join(education.get('courses', []))\n",
    "\n",
    "    education_paragraph += f\"Institution: {institution}\\n\"\n",
    "    education_paragraph += f\"Area of Study: {area}\\n\"\n",
    "    education_paragraph += f\"Degree: {study_type}\\n\"\n",
    "    education_paragraph += f\"Start Date: {start_date}\\n\"\n",
    "    education_paragraph += f\"End Date: {end_date}\\n\"\n",
    "    if courses:\n",
    "        education_paragraph += f\"Courses: {courses}\\n\"\n",
    "    education_paragraph += \"\\n\"\n",
    "\n",
    "# Display the paragraph\n",
    "print(education_paragraph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               work  \\\n",
      "0  10554236  Position: Accountant\\nCompany: Company Name\\nS...   \n",
      "\n",
      "                                           education  \n",
      "0  Institution: Northern Maine Community College\\...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Get the filename from the path\n",
    "file_path = '..\\\\output_json\\\\ACCOUNTANT\\\\10554236.json'\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Extract the id from the filename\n",
    "cv_id = os.path.splitext(file_name)[0]  # Assuming the format is something like '10554236.json'\n",
    "\n",
    "# Load JSON from the file\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        cv_data = json.load(file)\n",
    "\n",
    "    # Extract 'work' section and combine them into a paragraph\n",
    "    work_paragraph = \"\"\n",
    "    for work in cv_data.get('work', []):\n",
    "        work_summary = work.get('summary', '')\n",
    "        work_highlights = ', '.join(work.get('highlights', []))\n",
    "        if work_summary or work_highlights:\n",
    "            work_paragraph += f\"Position: {work.get('position', '')}\\n\"\n",
    "            work_paragraph += f\"Company: {work.get('name', '')}\\n\"\n",
    "            work_paragraph += f\"Summary: {work_summary}\\n\"\n",
    "            if work_highlights:\n",
    "                work_paragraph += f\"Highlights: {work_highlights}\\n\"\n",
    "            work_paragraph += \"\\n\"\n",
    "\n",
    "    # Extract 'education' section and combine them into a paragraph\n",
    "    education_paragraph = \"\"\n",
    "    for education in cv_data.get('education', []):\n",
    "        institution = education.get('institution', '')\n",
    "        area = education.get('area', '')\n",
    "        study_type = education.get('studyType', '')\n",
    "        start_date = education.get('startDate', '')\n",
    "        end_date = education.get('endDate', '')\n",
    "        courses = ', '.join(education.get('courses', []))\n",
    "\n",
    "        education_paragraph += f\"Institution: {institution}\\n\"\n",
    "        education_paragraph += f\"Area of Study: {area}\\n\"\n",
    "        education_paragraph += f\"Degree: {study_type}\\n\"\n",
    "        education_paragraph += f\"Start Date: {start_date}\\n\"\n",
    "        education_paragraph += f\"End Date: {end_date}\\n\"\n",
    "        if courses:\n",
    "            education_paragraph += f\"Courses: {courses}\\n\"\n",
    "        education_paragraph += \"\\n\"\n",
    "\n",
    "    # Create a DataFrame with 'id', 'work', and 'education' columns\n",
    "    df = pd.DataFrame({\n",
    "        'id': [cv_id],\n",
    "        'work': [work_paragraph],\n",
    "        'education': [education_paragraph]\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(df)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               work  \\\n",
      "0  10554236  Position: Accountant\\nCompany: Company Name\\nS...   \n",
      "\n",
      "                                           education  \\\n",
      "0  Institution: Northern Maine Community College\\...   \n",
      "\n",
      "                                     skills_projects  \n",
      "0  Skill: Accounting\\n\\nSkill: General Accounting...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Get the filename from the path\n",
    "file_path = '..\\\\output_json\\\\ACCOUNTANT\\\\10554236.json'\n",
    "file_name = os.path.basename(file_path)\n",
    "\n",
    "# Extract the id from the filename\n",
    "cv_id = os.path.splitext(file_name)[0]  # Assuming the format is something like '10554236.json'\n",
    "\n",
    "# Load JSON from the file\n",
    "try:\n",
    "    with open(file_path, 'r') as file:\n",
    "        cv_data = json.load(file)\n",
    "\n",
    "    # Extract 'work' section and combine them into a paragraph\n",
    "    work_paragraph = \"\"\n",
    "    for work in cv_data.get('work', []):\n",
    "        work_summary = work.get('summary', '')\n",
    "        work_highlights = ', '.join(work.get('highlights', []))\n",
    "        if work_summary or work_highlights:\n",
    "            work_paragraph += f\"Position: {work.get('position', '')}\\n\"\n",
    "            work_paragraph += f\"Company: {work.get('name', '')}\\n\"\n",
    "            work_paragraph += f\"Summary: {work_summary}\\n\"\n",
    "            if work_highlights:\n",
    "                work_paragraph += f\"Highlights: {work_highlights}\\n\"\n",
    "            work_paragraph += \"\\n\"\n",
    "\n",
    "    # Extract 'education' section and combine them into a paragraph\n",
    "    education_paragraph = \"\"\n",
    "    for education in cv_data.get('education', []):\n",
    "        institution = education.get('institution', '')\n",
    "        area = education.get('area', '')\n",
    "        study_type = education.get('studyType', '')\n",
    "        start_date = education.get('startDate', '')\n",
    "        end_date = education.get('endDate', '')\n",
    "        courses = ', '.join(education.get('courses', []))\n",
    "\n",
    "        education_paragraph += f\"Institution: {institution}\\n\"\n",
    "        education_paragraph += f\"Area of Study: {area}\\n\"\n",
    "        education_paragraph += f\"Degree: {study_type}\\n\"\n",
    "        education_paragraph += f\"Start Date: {start_date}\\n\"\n",
    "        education_paragraph += f\"End Date: {end_date}\\n\"\n",
    "        if courses:\n",
    "            education_paragraph += f\"Courses: {courses}\\n\"\n",
    "        education_paragraph += \"\\n\"\n",
    "\n",
    "    # Extract 'skills' and 'projects' sections and combine them into a single paragraph\n",
    "    skills_projects_paragraph = \"\"\n",
    "    for skills in cv_data.get('skills', []):\n",
    "        skill_name = skills.get('name', '')\n",
    "        skill_level = skills.get('level', '')\n",
    "        skill_keywords = ', '.join(skills.get('keywords', []))\n",
    "\n",
    "        skills_projects_paragraph += f\"Skill: {skill_name}\\n\"\n",
    "        if skill_level:\n",
    "            skills_projects_paragraph += f\"Level: {skill_level}\\n\"\n",
    "        if skill_keywords:\n",
    "            skills_projects_paragraph += f\"Keywords: {skill_keywords}\\n\"\n",
    "        skills_projects_paragraph += \"\\n\"\n",
    "\n",
    "    # Create a DataFrame with 'id', 'work', 'education', and 'skills_projects' columns\n",
    "    df = pd.DataFrame({\n",
    "        'id': [cv_id],\n",
    "        'work': [work_paragraph],\n",
    "        'education': [education_paragraph],\n",
    "        'skills_projects': [skills_projects_paragraph]\n",
    "    })\n",
    "\n",
    "    # Display the DataFrame\n",
    "    # print(df.head())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {file_path} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSONDecodeError: Expecting value: line 20 column 2 (char 1220)\n",
      "JSONDecodeError: Extra data: line 98 column 1 (char 3436)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 33 column 5 (char 1731)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Invalid control character at: line 20 column 453 (char 1094)\n",
      "JSONDecodeError: Expecting value: line 43 column 3 (char 2631)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 117 column 48 (char 3334)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 26 column 9 (char 883)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 73 column 5 (char 2561)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 96 column 1 (char 2567)\n",
      "JSONDecodeError: Expecting value: line 31 column 7 (char 1890)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 58 column 1 (char 1991)\n",
      "JSONDecodeError: Expecting value: line 29 column 5 (char 1387)\n",
      "JSONDecodeError: Expecting value: line 29 column 5 (char 1018)\n",
      "JSONDecodeError: Expecting value: line 49 column 4 (char 1794)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 160 column 3 (char 4843)\n",
      "JSONDecodeError: Expecting ':' delimiter: line 15 column 15 (char 394)\n",
      "JSONDecodeError: Extra data: line 112 column 1 (char 3388)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 37 column 9 (char 1518)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 80 column 16 (char 4040)\n",
      "JSONDecodeError: Expecting value: line 105 column 20 (char 3274)\n",
      "JSONDecodeError: Expecting value: line 34 column 5 (char 1120)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 22 column 5 (char 819)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 29 column 6 (char 890)\n",
      "JSONDecodeError: Extra data: line 158 column 1 (char 2966)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 122 column 1 (char 3643)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 94 column 3 (char 3639)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 38 column 5 (char 1076)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 58 column 5 (char 3168)\n",
      "JSONDecodeError: Extra data: line 163 column 1 (char 6094)\n",
      "JSONDecodeError: Extra data: line 82 column 1 (char 2699)\n",
      "JSONDecodeError: Expecting value: line 38 column 5 (char 1635)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 126 column 5 (char 3343)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 125 column 1 (char 4033)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 32 column 9 (char 1708)\n",
      "JSONDecodeError: Expecting value: line 29 column 5 (char 1085)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 114 column 1 (char 4201)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 83 column 9 (char 3034)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 37 column 6 (char 1598)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 157 column 1 (char 4405)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 60 column 5 (char 4346)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 41 column 5 (char 2012)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Invalid control character at: line 26 column 81 (char 757)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 7 column 2 (char 473)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Invalid control character at: line 146 column 155 (char 4804)\n",
      "JSONDecodeError: Extra data: line 3 column 1 (char 852)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 38 column 5 (char 2076)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 115 column 1 (char 3670)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 47 column 5 (char 3065)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 11 column 5 (char 520)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 38 column 5 (char 1604)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 90 column 2 (char 4200)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 22 column 243 (char 1011)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 37 column 5 (char 1262)\n",
      "JSONDecodeError: Expecting value: line 33 column 4 (char 1191)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 28 column 5 (char 1181)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 96 column 5 (char 3375)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 17 column 5 (char 456)\n",
      "JSONDecodeError: Expecting value: line 33 column 5 (char 1351)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 116 column 3 (char 4155)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 125 column 3 (char 3268)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 23 column 5 (char 1382)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 29 column 5 (char 1404)\n",
      "JSONDecodeError: Expecting value: line 32 column 9 (char 1353)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 45 column 5 (char 1897)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 90 column 1 (char 3339)\n",
      "JSONDecodeError: Expecting value: line 107 column 5 (char 2971)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 18 column 3 (char 511)\n",
      "JSONDecodeError: Expecting value: line 38 column 5 (char 2286)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 25 column 75 (char 729)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 104 column 3 (char 4981)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 18 column 5 (char 722)\n",
      "JSONDecodeError: Expecting value: line 108 column 5 (char 3199)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 24 column 97 (char 952)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 128 column 1 (char 4080)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Extra data: line 104 column 1 (char 4205)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting ',' delimiter: line 85 column 154 (char 2297)\n",
      "JSONDecodeError: Expecting property name enclosed in double quotes: line 6 column 5 (char 507)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "            id                category  \\\n",
      "0     10554236              ACCOUNTANT   \n",
      "1     10674770              ACCOUNTANT   \n",
      "2     11163645              ACCOUNTANT   \n",
      "3     11759079              ACCOUNTANT   \n",
      "4     12065211              ACCOUNTANT   \n",
      "...        ...                     ...   \n",
      "1369  83816738  INFORMATION-TECHNOLOGY   \n",
      "1370  89413122  INFORMATION-TECHNOLOGY   \n",
      "1371  91121135  INFORMATION-TECHNOLOGY   \n",
      "1372  91635250  INFORMATION-TECHNOLOGY   \n",
      "1373  92069209  INFORMATION-TECHNOLOGY   \n",
      "\n",
      "                                                   work  \\\n",
      "0     Position: Accountant\\nCompany: Company Name\\nS...   \n",
      "1     Position: Staff Accountant\\nCompany: Company N...   \n",
      "2     Position: Accountant\\nCompany: Company Name\\nS...   \n",
      "3     Position: Senior Accountant\\nCompany: Company ...   \n",
      "4     Position: Senior Accountant\\nCompany: Company ...   \n",
      "...                                                 ...   \n",
      "1369  Position: Information Technology Intern (Test ...   \n",
      "1370  Position: Operations Research Analyst\\nCompany...   \n",
      "1371  Position: Administrative Assistant Director, H...   \n",
      "1372  Position: Information Technology Specialist\\nC...   \n",
      "1373  Position: Director of Information Technology\\n...   \n",
      "\n",
      "                                              education  \\\n",
      "0     Institution: Northern Maine Community College\\...   \n",
      "1     Institution: University of North Carolina\\nAre...   \n",
      "2     Institution: Martinez Adult Education, Busines...   \n",
      "3     Institution: EMORY UNIVERSITY, Goizueta Busine...   \n",
      "4     Institution: TEMPLE UNIVERSITY\\nArea of Study:...   \n",
      "...                                                 ...   \n",
      "1369  Institution: Lamar University\\nArea of Study: ...   \n",
      "1370  Institution: New York University\\nArea of Stud...   \n",
      "1371  Institution: Virginia High School\\nArea of Stu...   \n",
      "1372  Institution: University Of Advancing Technolog...   \n",
      "1373  Institution: UNC-Chapel Hill\\nArea of Study: I...   \n",
      "\n",
      "                                        skills_projects  \n",
      "0     Skill: Accounting\\n\\nSkill: General Accounting...  \n",
      "1     Skill: Accounting\\nLevel: Master\\nKeywords: Qu...  \n",
      "2     Skill: Accounting\\nLevel: Advanced\\nKeywords: ...  \n",
      "3     Skill: Accounting\\nLevel: Senior\\nKeywords: ac...  \n",
      "4     Skill: Accounting\\nLevel: Senior\\nKeywords: Ad...  \n",
      "...                                                 ...  \n",
      "1369  Skill: Java/J2EE\\n\\nSkill: JavaScript\\n\\nSkill...  \n",
      "1370  Skill: Project Management\\n\\nSkill: Informatio...  \n",
      "1371  Skill: Administrative Skills\\nKeywords: Traini...  \n",
      "1372  Skill: Information Technology\\nKeywords: Route...  \n",
      "1373  Skill: Information Technology Management\\nKeyw...  \n",
      "\n",
      "[1374 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "def process_json(file_path, folder_name):\n",
    "    # Get the filename from the path\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "    # Extract the id from the filename\n",
    "    cv_id = os.path.splitext(file_name)[0]  # Assuming the format is something like '10554236.json'\n",
    "\n",
    "    # Load JSON from the file\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            cv_data = json.load(file)\n",
    "\n",
    "        # Extract 'work' section and combine them into a paragraph\n",
    "        work_paragraph = \"\"\n",
    "        for work in cv_data.get('work', []):\n",
    "            work_summary = work.get('summary', '')\n",
    "            work_highlights = ', '.join(work.get('highlights', []))\n",
    "            if work_summary or work_highlights:\n",
    "                work_paragraph += f\"Position: {work.get('position', '')}\\n\"\n",
    "                work_paragraph += f\"Company: {work.get('name', '')}\\n\"\n",
    "                work_paragraph += f\"Summary: {work_summary}\\n\"\n",
    "                if work_highlights:\n",
    "                    work_paragraph += f\"Highlights: {work_highlights}\\n\"\n",
    "                work_paragraph += \"\\n\"\n",
    "\n",
    "        # Extract 'education' section and combine them into a paragraph\n",
    "        education_paragraph = \"\"\n",
    "        for education in cv_data.get('education', []):\n",
    "            institution = education.get('institution', '')\n",
    "            area = education.get('area', '')\n",
    "            study_type = education.get('studyType', '')\n",
    "            start_date = education.get('startDate', '')\n",
    "            end_date = education.get('endDate', '')\n",
    "            courses = ', '.join(education.get('courses', []))\n",
    "\n",
    "            education_paragraph += f\"Institution: {institution}\\n\"\n",
    "            education_paragraph += f\"Area of Study: {area}\\n\"\n",
    "            education_paragraph += f\"Degree: {study_type}\\n\"\n",
    "            education_paragraph += f\"Start Date: {start_date}\\n\"\n",
    "            education_paragraph += f\"End Date: {end_date}\\n\"\n",
    "            if courses:\n",
    "                education_paragraph += f\"Courses: {courses}\\n\"\n",
    "            education_paragraph += \"\\n\"\n",
    "\n",
    "        # Extract 'skills' section and combine them into a paragraph\n",
    "        skills_projects_paragraph = \"\"\n",
    "        for skills in cv_data.get('skills', []):\n",
    "            skill_name = skills.get('name', '')\n",
    "            skill_level = skills.get('level', '')\n",
    "            skill_keywords = ', '.join(skills.get('keywords', []))\n",
    "\n",
    "            skills_projects_paragraph += f\"Skill: {skill_name}\\n\"\n",
    "            if skill_level:\n",
    "                skills_projects_paragraph += f\"Level: {skill_level}\\n\"\n",
    "            if skill_keywords:\n",
    "                skills_projects_paragraph += f\"Keywords: {skill_keywords}\\n\"\n",
    "            skills_projects_paragraph += \"\\n\"\n",
    "\n",
    "        # Create a DataFrame with 'id', 'folder_name', 'work', 'education', and 'skills_projects' columns\n",
    "        df = pd.DataFrame({\n",
    "            'id': [cv_id],\n",
    "            'category': [folder_name],\n",
    "            'work': [work_paragraph],\n",
    "            'education': [education_paragraph],\n",
    "            'skills_projects': [skills_projects_paragraph]\n",
    "        })\n",
    "\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_folder(folder_path):\n",
    "    all_data = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                folder_name = os.path.basename(root)\n",
    "                df = process_json(file_path, folder_name)\n",
    "                if df is not None:\n",
    "                    all_data.append(df)\n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Specify the main folder containing subfolders like ACCOUNTANT, IT, etc.\n",
    "folder_path = '../output_json'\n",
    "final_df = process_folder(folder_path)\n",
    "\n",
    "# Display the final DataFrame\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>work</th>\n",
       "      <th>education</th>\n",
       "      <th>skills_projects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10554236</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>Position: Accountant\\nCompany: Company Name\\nS...</td>\n",
       "      <td>Institution: Northern Maine Community College\\...</td>\n",
       "      <td>Skill: Accounting\\n\\nSkill: General Accounting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10674770</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>Position: Staff Accountant\\nCompany: Company N...</td>\n",
       "      <td>Institution: University of North Carolina\\nAre...</td>\n",
       "      <td>Skill: Accounting\\nLevel: Master\\nKeywords: Qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11163645</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>Position: Accountant\\nCompany: Company Name\\nS...</td>\n",
       "      <td>Institution: Martinez Adult Education, Busines...</td>\n",
       "      <td>Skill: Accounting\\nLevel: Advanced\\nKeywords: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11759079</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>Position: Senior Accountant\\nCompany: Company ...</td>\n",
       "      <td>Institution: EMORY UNIVERSITY, Goizueta Busine...</td>\n",
       "      <td>Skill: Accounting\\nLevel: Senior\\nKeywords: ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12065211</td>\n",
       "      <td>ACCOUNTANT</td>\n",
       "      <td>Position: Senior Accountant\\nCompany: Company ...</td>\n",
       "      <td>Institution: TEMPLE UNIVERSITY\\nArea of Study:...</td>\n",
       "      <td>Skill: Accounting\\nLevel: Senior\\nKeywords: Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>83816738</td>\n",
       "      <td>INFORMATION-TECHNOLOGY</td>\n",
       "      <td>Position: Information Technology Intern (Test ...</td>\n",
       "      <td>Institution: Lamar University\\nArea of Study: ...</td>\n",
       "      <td>Skill: Java/J2EE\\n\\nSkill: JavaScript\\n\\nSkill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>89413122</td>\n",
       "      <td>INFORMATION-TECHNOLOGY</td>\n",
       "      <td>Position: Operations Research Analyst\\nCompany...</td>\n",
       "      <td>Institution: New York University\\nArea of Stud...</td>\n",
       "      <td>Skill: Project Management\\n\\nSkill: Informatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>91121135</td>\n",
       "      <td>INFORMATION-TECHNOLOGY</td>\n",
       "      <td>Position: Administrative Assistant Director, H...</td>\n",
       "      <td>Institution: Virginia High School\\nArea of Stu...</td>\n",
       "      <td>Skill: Administrative Skills\\nKeywords: Traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>91635250</td>\n",
       "      <td>INFORMATION-TECHNOLOGY</td>\n",
       "      <td>Position: Information Technology Specialist\\nC...</td>\n",
       "      <td>Institution: University Of Advancing Technolog...</td>\n",
       "      <td>Skill: Information Technology\\nKeywords: Route...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>92069209</td>\n",
       "      <td>INFORMATION-TECHNOLOGY</td>\n",
       "      <td>Position: Director of Information Technology\\n...</td>\n",
       "      <td>Institution: UNC-Chapel Hill\\nArea of Study: I...</td>\n",
       "      <td>Skill: Information Technology Management\\nKeyw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1374 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                category  \\\n",
       "0     10554236              ACCOUNTANT   \n",
       "1     10674770              ACCOUNTANT   \n",
       "2     11163645              ACCOUNTANT   \n",
       "3     11759079              ACCOUNTANT   \n",
       "4     12065211              ACCOUNTANT   \n",
       "...        ...                     ...   \n",
       "1369  83816738  INFORMATION-TECHNOLOGY   \n",
       "1370  89413122  INFORMATION-TECHNOLOGY   \n",
       "1371  91121135  INFORMATION-TECHNOLOGY   \n",
       "1372  91635250  INFORMATION-TECHNOLOGY   \n",
       "1373  92069209  INFORMATION-TECHNOLOGY   \n",
       "\n",
       "                                                   work  \\\n",
       "0     Position: Accountant\\nCompany: Company Name\\nS...   \n",
       "1     Position: Staff Accountant\\nCompany: Company N...   \n",
       "2     Position: Accountant\\nCompany: Company Name\\nS...   \n",
       "3     Position: Senior Accountant\\nCompany: Company ...   \n",
       "4     Position: Senior Accountant\\nCompany: Company ...   \n",
       "...                                                 ...   \n",
       "1369  Position: Information Technology Intern (Test ...   \n",
       "1370  Position: Operations Research Analyst\\nCompany...   \n",
       "1371  Position: Administrative Assistant Director, H...   \n",
       "1372  Position: Information Technology Specialist\\nC...   \n",
       "1373  Position: Director of Information Technology\\n...   \n",
       "\n",
       "                                              education  \\\n",
       "0     Institution: Northern Maine Community College\\...   \n",
       "1     Institution: University of North Carolina\\nAre...   \n",
       "2     Institution: Martinez Adult Education, Busines...   \n",
       "3     Institution: EMORY UNIVERSITY, Goizueta Busine...   \n",
       "4     Institution: TEMPLE UNIVERSITY\\nArea of Study:...   \n",
       "...                                                 ...   \n",
       "1369  Institution: Lamar University\\nArea of Study: ...   \n",
       "1370  Institution: New York University\\nArea of Stud...   \n",
       "1371  Institution: Virginia High School\\nArea of Stu...   \n",
       "1372  Institution: University Of Advancing Technolog...   \n",
       "1373  Institution: UNC-Chapel Hill\\nArea of Study: I...   \n",
       "\n",
       "                                        skills_projects  \n",
       "0     Skill: Accounting\\n\\nSkill: General Accounting...  \n",
       "1     Skill: Accounting\\nLevel: Master\\nKeywords: Qu...  \n",
       "2     Skill: Accounting\\nLevel: Advanced\\nKeywords: ...  \n",
       "3     Skill: Accounting\\nLevel: Senior\\nKeywords: ac...  \n",
       "4     Skill: Accounting\\nLevel: Senior\\nKeywords: Ad...  \n",
       "...                                                 ...  \n",
       "1369  Skill: Java/J2EE\\n\\nSkill: JavaScript\\n\\nSkill...  \n",
       "1370  Skill: Project Management\\n\\nSkill: Informatio...  \n",
       "1371  Skill: Administrative Skills\\nKeywords: Traini...  \n",
       "1372  Skill: Information Technology\\nKeywords: Route...  \n",
       "1373  Skill: Information Technology Management\\nKeyw...  \n",
       "\n",
       "[1374 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files with JSON errors:\n",
      "../output_json\\ACCOUNTANT\\17556527.json\n",
      "../output_json\\ACCOUNTANT\\18569929.json\n",
      "../output_json\\ACCOUNTANT\\20253563.json\n",
      "../output_json\\ACCOUNTANT\\24103168.json\n",
      "../output_json\\ACCOUNTANT\\24703009.json\n",
      "../output_json\\ACCOUNTANT\\27558837.json\n",
      "../output_json\\ACCOUNTANT\\28939941.json\n",
      "../output_json\\ACCOUNTANT\\29456173.json\n",
      "../output_json\\ACCOUNTANT\\36024962.json\n",
      "../output_json\\ACCOUNTANT\\39115899.json\n",
      "../output_json\\ACCOUNTANT\\43685045.json\n",
      "../output_json\\ACCOUNTANT\\78403342.json\n",
      "../output_json\\ADVOCATE\\10818478.json\n",
      "../output_json\\ADVOCATE\\11773767.json\n",
      "../output_json\\ADVOCATE\\13115648.json\n",
      "../output_json\\ADVOCATE\\13809698.json\n",
      "../output_json\\ADVOCATE\\18725071.json\n",
      "../output_json\\ADVOCATE\\18997135.json\n",
      "../output_json\\ADVOCATE\\19518606.json\n",
      "../output_json\\ADVOCATE\\22042181.json\n",
      "../output_json\\ADVOCATE\\26071861.json\n",
      "../output_json\\ADVOCATE\\27182111.json\n",
      "../output_json\\ADVOCATE\\29177904.json\n",
      "../output_json\\ADVOCATE\\42164460.json\n",
      "../output_json\\ADVOCATE\\47133747.json\n",
      "../output_json\\ADVOCATE\\75950464.json\n",
      "../output_json\\AGRICULTURE\\11676151.json\n",
      "../output_json\\AGRICULTURE\\14140903.json\n",
      "../output_json\\AGRICULTURE\\17499196.json\n",
      "../output_json\\AGRICULTURE\\17640785.json\n",
      "../output_json\\AGRICULTURE\\19532392.json\n",
      "../output_json\\AGRICULTURE\\20006992.json\n",
      "../output_json\\AGRICULTURE\\20969119.json\n",
      "../output_json\\AGRICULTURE\\24397882.json\n",
      "../output_json\\AGRICULTURE\\24416961.json\n",
      "../output_json\\AGRICULTURE\\26835781.json\n",
      "../output_json\\AGRICULTURE\\26921245.json\n",
      "../output_json\\AGRICULTURE\\29968330.json\n",
      "../output_json\\AGRICULTURE\\38216888.json\n",
      "../output_json\\AGRICULTURE\\69360287.json\n",
      "../output_json\\APPAREL\\12059610.json\n",
      "../output_json\\APPAREL\\16985289.json\n",
      "../output_json\\APPAREL\\27549075.json\n",
      "../output_json\\APPAREL\\29521434.json\n",
      "../output_json\\APPAREL\\29640922.json\n",
      "../output_json\\APPAREL\\30430249.json\n",
      "../output_json\\APPAREL\\31761591.json\n",
      "../output_json\\APPAREL\\54308684.json\n",
      "../output_json\\APPAREL\\58208591.json\n",
      "../output_json\\APPAREL\\91533580.json\n",
      "../output_json\\ARTS\\12413512.json\n",
      "../output_json\\ARTS\\13272204.json\n",
      "../output_json\\ARTS\\16244633.json\n",
      "../output_json\\ARTS\\17033567.json\n",
      "../output_json\\ARTS\\17325147.json\n",
      "../output_json\\ARTS\\24349611.json\n",
      "../output_json\\ARTS\\25157655.json\n",
      "../output_json\\ARTS\\25926667.json\n",
      "../output_json\\ARTS\\39064638.json\n",
      "../output_json\\ARTS\\39470264.json\n",
      "../output_json\\AUTOMOBILE\\18932512.json\n",
      "../output_json\\AUTOMOBILE\\22732234.json\n",
      "../output_json\\AUTOMOBILE\\24703983.json\n",
      "../output_json\\AUTOMOBILE\\97449528.json\n",
      "../output_json\\AVIATION\\11752500.json\n",
      "../output_json\\AVIATION\\12144825.json\n",
      "../output_json\\AVIATION\\17686472.json\n",
      "../output_json\\AVIATION\\19818707.json\n",
      "../output_json\\AVIATION\\23464505.json\n",
      "../output_json\\AVIATION\\24589765.json\n",
      "../output_json\\AVIATION\\27902692.json\n",
      "../output_json\\AVIATION\\31536294.json\n",
      "../output_json\\BANKING\\11266906.json\n",
      "../output_json\\BANKING\\12021752.json\n",
      "../output_json\\BANKING\\17189156.json\n",
      "../output_json\\BANKING\\18645964.json\n",
      "../output_json\\BANKING\\19437318.json\n",
      "../output_json\\BANKING\\26987539.json\n",
      "../output_json\\BANKING\\31025785.json\n",
      "../output_json\\BANKING\\72876163.json\n",
      "../output_json\\BANKING\\96493528.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\10235211.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\10289113.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\12632728.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\13888506.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\14241621.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\17095812.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\18757174.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\19738730.json\n",
      "../output_json\\BUSINESS-DEVELOPMENT\\30938994.json\n",
      "../output_json\\CHEF\\11444536.json\n",
      "../output_json\\CHEF\\13212436.json\n",
      "../output_json\\CHEF\\16594812.json\n",
      "../output_json\\CHEF\\19285236.json\n",
      "../output_json\\CHEF\\20321582.json\n",
      "../output_json\\CHEF\\21101152.json\n",
      "../output_json\\CHEF\\21611637.json\n",
      "../output_json\\CHEF\\23841877.json\n",
      "../output_json\\CHEF\\25128608.json\n",
      "../output_json\\CHEF\\29072179.json\n",
      "../output_json\\CHEF\\51554903.json\n",
      "../output_json\\CHEF\\94047639.json\n",
      "../output_json\\CONSTRUCTION\\10281555.json\n",
      "../output_json\\CONSTRUCTION\\12654876.json\n",
      "../output_json\\CONSTRUCTION\\12839152.json\n",
      "../output_json\\ENGINEERING\\10985403.json\n",
      "../output_json\\ENGINEERING\\17488801.json\n",
      "../output_json\\ENGINEERING\\26456899.json\n",
      "../output_json\\ENGINEERING\\27756469.json\n",
      "../output_json\\ENGINEERING\\28923650.json\n",
      "../output_json\\ENGINEERING\\35172961.json\n",
      "../output_json\\ENGINEERING\\54227873.json\n",
      "../output_json\\FINANCE\\18072085.json\n",
      "../output_json\\FINANCE\\20918464.json\n",
      "../output_json\\FINANCE\\20969845.json\n",
      "../output_json\\FINANCE\\23354541.json\n",
      "../output_json\\FINANCE\\24530382.json\n",
      "../output_json\\FINANCE\\26231609.json\n",
      "../output_json\\FINANCE\\27018361.json\n",
      "../output_json\\FINANCE\\37931076.json\n",
      "../output_json\\FINANCE\\59450123.json\n",
      "../output_json\\FINANCE\\66741193.json\n",
      "../output_json\\FINANCE\\72136463.json\n",
      "../output_json\\FINANCE\\95519832.json\n",
      "../output_json\\HEALTHCARE\\11378657.json\n",
      "../output_json\\HEALTHCARE\\15680735.json\n",
      "../output_json\\HEALTHCARE\\18129173.json\n",
      "../output_json\\HEALTHCARE\\23814777.json\n",
      "../output_json\\HEALTHCARE\\25328428.json\n",
      "../output_json\\HEALTHCARE\\28745844.json\n",
      "../output_json\\HEALTHCARE\\36861863.json\n",
      "../output_json\\HEALTHCARE\\43994605.json\n",
      "../output_json\\HEALTHCARE\\47996197.json\n",
      "../output_json\\HEALTHCARE\\75744306.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\10247517.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\10840430.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\11957080.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\15802627.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\16899268.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\18176523.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\19201175.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\20237244.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\25990239.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\28126340.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\29051656.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\36434348.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\57002858.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\90867631.json\n",
      "../output_json\\INFORMATION-TECHNOLOGY\\91697974.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def find_files_with_errors(directory):\n",
    "    error_files = []\n",
    "\n",
    "    # Walk through the directory and its subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    with open(file_path, 'r') as f:\n",
    "                        json.load(f)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    error_files.append(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "    \n",
    "    return error_files\n",
    "\n",
    "# Example usage\n",
    "directory_path = '../output_json'\n",
    "error_files = find_files_with_errors(directory_path)\n",
    "\n",
    "print(\"Files with JSON errors:\")\n",
    "for error_file in error_files:\n",
    "    print(error_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"../data/cv data/cv_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
